{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/BastienCherel/Advanced-ML-I/blob/main/Lab4_AutoML_Application.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Cs4wBV7sWGR"
   },
   "source": [
    "## Lab 4: Introduction to AutoML Using TPOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REpfqVxCsWGT"
   },
   "source": [
    "### **Objective**:\n",
    "In this lab, you will explore Automated Machine Learning (AutoML), focusing on the TPOT library, which automates the process of feature selection, model selection, and hyperparameter optimization using genetic programming. By the end of this lab, you’ll understand how to leverage TPOT for automating the model building pipeline.\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "•\tBasic knowledge of Machine Learning.\n",
    "\n",
    "•\tFamiliarity with supervised learning models and the concept of model evaluation metrics.\n",
    "\n",
    "•\tRequired Libraries: pandas, sklearn, TPOT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4PZNzBisWGU"
   },
   "source": [
    "### **1. Introduction to AutoML and TPOT**\n",
    "\n",
    "AutoML helps automate the end-to-end process of applying machine learning models to real-world problems. It assists with tasks like:\n",
    "\n",
    "•\tPreprocessing data.\n",
    "\n",
    "•\tSelecting features.\n",
    "\n",
    "•\tTuning hyperparameters.\n",
    "\n",
    "•\tTraining models.\n",
    "\n",
    "TPOT (Tree-based Pipeline Optimization Tool) is a Python library that uses genetic programming to automate the machine learning pipeline. It automatically optimizes models and discovers the best pipeline for a given dataset.\n",
    "\n",
    "#### **Step 1.1: Install Required Libraries**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Y3Rg2T5msWGU",
    "outputId": "499a0b11-ac43-4554-ac58-8fb3ac3818a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tpot in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.12.2)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /home/codespace/.local/lib/python3.12/site-packages (from tpot) (2.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from tpot) (1.14.1)\n",
      "Requirement already satisfied: deap>=1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tpot) (1.4.1)\n",
      "Requirement already satisfied: update-checker>=0.16 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tpot) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tpot) (4.67.1)\n",
      "Requirement already satisfied: stopit>=1.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tpot) (1.1.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /home/codespace/.local/lib/python3.12/site-packages (from tpot) (1.4.2)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tpot) (2.1.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from update-checker>=0.16->tpot) (2.32.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from xgboost>=1.1.0->tpot) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install TPOT (if not installed)\n",
    "%pip install tpot scikit-learn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdJD6j8CsWGV"
   },
   "source": [
    "### **2. Load and Explore the Dataset**\n",
    "\n",
    "In this step, we’ll load a dataset to be used with AutoML. We’ll work with the breast cancer dataset from sklearn.\n",
    "\n",
    "#### **Step 2.1: Load the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aOxPQfnZsWGV",
    "outputId": "935ec48f-4cbf-4faf-facb-07e5453af67c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>13.74</td>\n",
       "      <td>17.91</td>\n",
       "      <td>88.12</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0.07944</td>\n",
       "      <td>0.06376</td>\n",
       "      <td>0.02881</td>\n",
       "      <td>0.01329</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.05580</td>\n",
       "      <td>...</td>\n",
       "      <td>15.34</td>\n",
       "      <td>22.46</td>\n",
       "      <td>97.19</td>\n",
       "      <td>725.9</td>\n",
       "      <td>0.09711</td>\n",
       "      <td>0.1824</td>\n",
       "      <td>0.1564</td>\n",
       "      <td>0.06019</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>13.37</td>\n",
       "      <td>16.39</td>\n",
       "      <td>86.10</td>\n",
       "      <td>553.5</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0.07325</td>\n",
       "      <td>0.08092</td>\n",
       "      <td>0.02800</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.05823</td>\n",
       "      <td>...</td>\n",
       "      <td>14.26</td>\n",
       "      <td>22.75</td>\n",
       "      <td>91.99</td>\n",
       "      <td>632.1</td>\n",
       "      <td>0.10250</td>\n",
       "      <td>0.2531</td>\n",
       "      <td>0.3308</td>\n",
       "      <td>0.08978</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.07628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>14.69</td>\n",
       "      <td>13.98</td>\n",
       "      <td>98.22</td>\n",
       "      <td>656.1</td>\n",
       "      <td>0.10310</td>\n",
       "      <td>0.18360</td>\n",
       "      <td>0.14500</td>\n",
       "      <td>0.06300</td>\n",
       "      <td>0.2086</td>\n",
       "      <td>0.07406</td>\n",
       "      <td>...</td>\n",
       "      <td>16.46</td>\n",
       "      <td>18.34</td>\n",
       "      <td>114.10</td>\n",
       "      <td>809.2</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.3635</td>\n",
       "      <td>0.3219</td>\n",
       "      <td>0.11080</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.09208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>12.91</td>\n",
       "      <td>16.33</td>\n",
       "      <td>82.53</td>\n",
       "      <td>516.4</td>\n",
       "      <td>0.07941</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.03873</td>\n",
       "      <td>0.02377</td>\n",
       "      <td>0.1829</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>13.88</td>\n",
       "      <td>22.00</td>\n",
       "      <td>90.81</td>\n",
       "      <td>600.6</td>\n",
       "      <td>0.10970</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.1764</td>\n",
       "      <td>0.08235</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>0.06949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>13.62</td>\n",
       "      <td>23.23</td>\n",
       "      <td>87.19</td>\n",
       "      <td>573.2</td>\n",
       "      <td>0.09246</td>\n",
       "      <td>0.06747</td>\n",
       "      <td>0.02974</td>\n",
       "      <td>0.02443</td>\n",
       "      <td>0.1664</td>\n",
       "      <td>0.05801</td>\n",
       "      <td>...</td>\n",
       "      <td>15.35</td>\n",
       "      <td>29.09</td>\n",
       "      <td>97.58</td>\n",
       "      <td>729.8</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.07174</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.06953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "149        13.74         17.91           88.12      585.0          0.07944   \n",
       "124        13.37         16.39           86.10      553.5          0.07115   \n",
       "421        14.69         13.98           98.22      656.1          0.10310   \n",
       "195        12.91         16.33           82.53      516.4          0.07941   \n",
       "545        13.62         23.23           87.19      573.2          0.09246   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "149           0.06376         0.02881              0.01329         0.1473   \n",
       "124           0.07325         0.08092              0.02800         0.1422   \n",
       "421           0.18360         0.14500              0.06300         0.2086   \n",
       "195           0.05366         0.03873              0.02377         0.1829   \n",
       "545           0.06747         0.02974              0.02443         0.1664   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "149                 0.05580  ...         15.34          22.46   \n",
       "124                 0.05823  ...         14.26          22.75   \n",
       "421                 0.07406  ...         16.46          18.34   \n",
       "195                 0.05667  ...         13.88          22.00   \n",
       "545                 0.05801  ...         15.35          29.09   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "149            97.19       725.9           0.09711             0.1824   \n",
       "124            91.99       632.1           0.10250             0.2531   \n",
       "421           114.10       809.2           0.13120             0.3635   \n",
       "195            90.81       600.6           0.10970             0.1506   \n",
       "545            97.58       729.8           0.12160             0.1517   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "149           0.1564               0.06019          0.2350   \n",
       "124           0.3308               0.08978          0.2048   \n",
       "421           0.3219               0.11080          0.2827   \n",
       "195           0.1764               0.08235          0.3024   \n",
       "545           0.1049               0.07174          0.2642   \n",
       "\n",
       "     worst fractal dimension  \n",
       "149                  0.07014  \n",
       "124                  0.07628  \n",
       "421                  0.09208  \n",
       "195                  0.06949  \n",
       "545                  0.06953  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98Q3rOXqsWGW"
   },
   "source": [
    "#### **Step 2.2: Check Dataset Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TY3tMrdZsWGW",
    "outputId": "f34a7ad2-70cf-417e-d7dd-3bc94ec1ba4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (398, 30)\n",
      "Shape of y_train: (398,)\n",
      "\n",
      "Missing values:\n",
      " mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.176078</td>\n",
       "      <td>19.159171</td>\n",
       "      <td>92.256332</td>\n",
       "      <td>659.770854</td>\n",
       "      <td>0.095962</td>\n",
       "      <td>0.103303</td>\n",
       "      <td>0.088071</td>\n",
       "      <td>0.048440</td>\n",
       "      <td>0.180308</td>\n",
       "      <td>0.062664</td>\n",
       "      <td>...</td>\n",
       "      <td>16.287322</td>\n",
       "      <td>25.505553</td>\n",
       "      <td>107.363844</td>\n",
       "      <td>881.848241</td>\n",
       "      <td>0.131772</td>\n",
       "      <td>0.249086</td>\n",
       "      <td>0.268497</td>\n",
       "      <td>0.113839</td>\n",
       "      <td>0.288300</td>\n",
       "      <td>0.083537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.535730</td>\n",
       "      <td>4.214074</td>\n",
       "      <td>24.289529</td>\n",
       "      <td>358.865452</td>\n",
       "      <td>0.013766</td>\n",
       "      <td>0.051209</td>\n",
       "      <td>0.077836</td>\n",
       "      <td>0.037712</td>\n",
       "      <td>0.026871</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>...</td>\n",
       "      <td>4.799691</td>\n",
       "      <td>6.017564</td>\n",
       "      <td>33.083204</td>\n",
       "      <td>570.753903</td>\n",
       "      <td>0.023023</td>\n",
       "      <td>0.148622</td>\n",
       "      <td>0.196139</td>\n",
       "      <td>0.063886</td>\n",
       "      <td>0.062318</td>\n",
       "      <td>0.017518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.691000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>48.340000</td>\n",
       "      <td>170.400000</td>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>8.678000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>54.490000</td>\n",
       "      <td>223.600000</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.034320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.752500</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.805000</td>\n",
       "      <td>426.175000</td>\n",
       "      <td>0.085550</td>\n",
       "      <td>0.063407</td>\n",
       "      <td>0.029585</td>\n",
       "      <td>0.020692</td>\n",
       "      <td>0.161575</td>\n",
       "      <td>0.057665</td>\n",
       "      <td>...</td>\n",
       "      <td>13.075000</td>\n",
       "      <td>21.070000</td>\n",
       "      <td>84.542500</td>\n",
       "      <td>521.550000</td>\n",
       "      <td>0.114325</td>\n",
       "      <td>0.147325</td>\n",
       "      <td>0.116475</td>\n",
       "      <td>0.063885</td>\n",
       "      <td>0.247775</td>\n",
       "      <td>0.071155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.275000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>85.980000</td>\n",
       "      <td>546.250000</td>\n",
       "      <td>0.094625</td>\n",
       "      <td>0.091280</td>\n",
       "      <td>0.061880</td>\n",
       "      <td>0.034110</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>0.061325</td>\n",
       "      <td>...</td>\n",
       "      <td>14.975000</td>\n",
       "      <td>25.155000</td>\n",
       "      <td>97.745000</td>\n",
       "      <td>687.600000</td>\n",
       "      <td>0.131150</td>\n",
       "      <td>0.209250</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>0.099270</td>\n",
       "      <td>0.280750</td>\n",
       "      <td>0.080165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.090000</td>\n",
       "      <td>21.555000</td>\n",
       "      <td>105.625000</td>\n",
       "      <td>797.400000</td>\n",
       "      <td>0.104475</td>\n",
       "      <td>0.130575</td>\n",
       "      <td>0.127075</td>\n",
       "      <td>0.073963</td>\n",
       "      <td>0.195550</td>\n",
       "      <td>0.066007</td>\n",
       "      <td>...</td>\n",
       "      <td>18.707500</td>\n",
       "      <td>29.410000</td>\n",
       "      <td>125.300000</td>\n",
       "      <td>1061.250000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.341600</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.315650</td>\n",
       "      <td>0.091745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.311400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.218400</td>\n",
       "      <td>0.937900</td>\n",
       "      <td>0.903400</td>\n",
       "      <td>0.275600</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.173000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   398.000000    398.000000      398.000000   398.000000   \n",
       "mean     14.176078     19.159171       92.256332   659.770854   \n",
       "std       3.535730      4.214074       24.289529   358.865452   \n",
       "min       7.691000      9.710000       48.340000   170.400000   \n",
       "25%      11.752500     16.170000       75.805000   426.175000   \n",
       "50%      13.275000     18.700000       85.980000   546.250000   \n",
       "75%      16.090000     21.555000      105.625000   797.400000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       398.000000        398.000000      398.000000           398.000000   \n",
       "mean          0.095962          0.103303        0.088071             0.048440   \n",
       "std           0.013766          0.051209        0.077836             0.037712   \n",
       "min           0.062510          0.019380        0.000000             0.000000   \n",
       "25%           0.085550          0.063407        0.029585             0.020692   \n",
       "50%           0.094625          0.091280        0.061880             0.034110   \n",
       "75%           0.104475          0.130575        0.127075             0.073963   \n",
       "max           0.163400          0.311400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
       "count     398.000000              398.000000  ...    398.000000   \n",
       "mean        0.180308                0.062664  ...     16.287322   \n",
       "std         0.026871                0.007248  ...      4.799691   \n",
       "min         0.116700                0.049960  ...      8.678000   \n",
       "25%         0.161575                0.057665  ...     13.075000   \n",
       "50%         0.178800                0.061325  ...     14.975000   \n",
       "75%         0.195550                0.066007  ...     18.707500   \n",
       "max         0.304000                0.097440  ...     36.040000   \n",
       "\n",
       "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
       "count     398.000000       398.000000   398.000000        398.000000   \n",
       "mean       25.505553       107.363844   881.848241          0.131772   \n",
       "std         6.017564        33.083204   570.753903          0.023023   \n",
       "min        12.020000        54.490000   223.600000          0.081250   \n",
       "25%        21.070000        84.542500   521.550000          0.114325   \n",
       "50%        25.155000        97.745000   687.600000          0.131150   \n",
       "75%        29.410000       125.300000  1061.250000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.218400   \n",
       "\n",
       "       worst compactness  worst concavity  worst concave points  \\\n",
       "count         398.000000       398.000000            398.000000   \n",
       "mean            0.249086         0.268497              0.113839   \n",
       "std             0.148622         0.196139              0.063886   \n",
       "min             0.034320         0.000000              0.000000   \n",
       "25%             0.147325         0.116475              0.063885   \n",
       "50%             0.209250         0.226200              0.099270   \n",
       "75%             0.341600         0.384700              0.160400   \n",
       "max             0.937900         0.903400              0.275600   \n",
       "\n",
       "       worst symmetry  worst fractal dimension  \n",
       "count      398.000000               398.000000  \n",
       "mean         0.288300                 0.083537  \n",
       "std          0.062318                 0.017518  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.247775                 0.071155  \n",
       "50%          0.280750                 0.080165  \n",
       "75%          0.315650                 0.091745  \n",
       "max          0.663800                 0.173000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the dataset\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\\n\", X_train.isnull().sum())\n",
    "\n",
    "# Basic statistics of the dataset\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwtDnaIRsWGW"
   },
   "source": [
    "#### Discussion points:\n",
    "\n",
    "•\tExplore the dataset’s features and labels.\n",
    "\n",
    "•\tCheck if there are any missing values or preprocessing needed before applying TPOT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89WT5tG6sWGW"
   },
   "source": [
    "### **3. Introduction to TPOT**\n",
    "\n",
    "\n",
    "TPOT uses genetic algorithms to search for the best machine learning pipeline. It evaluates multiple pipelines, refines the best-performing ones, and finally returns the most optimized pipeline based on the given dataset.\n",
    "\n",
    "#### **Step 3.1: Initialize TPOT Classifier**\n",
    "\n",
    "We’ll use the TPOTClassifier for a binary classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5rrK_bdEsWGW",
    "outputId": "f714a19b-6c92-4bbd-a7d7-b39a72c0b163"
   },
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "# Initialize TPOTClassifier with hyperparameters\n",
    "tpot = TPOTClassifier(\n",
    "    generations=5,           # Number of iterations of the genetic algorithm\n",
    "    population_size=20,       # Size of the population in each generation\n",
    "    verbosity=2,              # Verbosity level (higher for more detailed output)\n",
    "    random_state=42,\n",
    "    n_jobs=-1                 # Use all available CPU cores\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUdWKPq_sWGX"
   },
   "source": [
    "#### **Step 3.2 Fit TPOT to the Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SujRImcxsWGX",
    "outputId": "15f9c068-c7bf-4a0d-a3ca-c9708551b9d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                             \n",
      "Generation 1 - Current best internal CV score: 0.9597784810126582\n",
      "                                                                             \n",
      "Generation 2 - Current best internal CV score: 0.9723734177215189\n",
      "                                                                             \n",
      "Generation 3 - Current best internal CV score: 0.9723734177215189\n",
      "                                                                             \n",
      "Generation 4 - Current best internal CV score: 0.9723734177215189\n",
      "                                                                              \n",
      "Generation 5 - Current best internal CV score: 0.9723734177215189\n",
      "                                                                              \n",
      "Best pipeline: MLPClassifier(RobustScaler(input_matrix), alpha=0.1, learning_rate_init=0.01)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TPOTClassifier(generations=5, n_jobs=-1, population_size=20, random_state=42,\n",
       "               verbosity=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TPOTClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TPOTClassifier(generations=5, n_jobs=-1, population_size=20, random_state=42,\n",
       "               verbosity=2)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TPOTClassifier(generations=5, n_jobs=-1, population_size=20, random_state=42,\n",
       "               verbosity=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the TPOTClassifier on the training data\n",
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aVg4XA6sWGX"
   },
   "source": [
    "\n",
    "**Note:** Training TPOT may take some time, as it evaluates many pipelines across generations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vjLKiV0sWGX"
   },
   "source": [
    "### **4. Evaluating the Performance of the TPOT Model**\n",
    "\n",
    "After training, TPOT will output the best pipeline it discovered. You can then evaluate the performance of the discovered pipeline on the test data.\n",
    "\n",
    "#### **Step 4.1: Evaluate on Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Cz-aAooYsWGX",
    "outputId": "588938e9-4012-447c-bc22-3ab68aa9e608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.66%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the model on the test set\n",
    "test_score = tpot.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poMcp1i_sWGX"
   },
   "source": [
    "#### **Step 4.2: Export the Discovered Pipeline**\n",
    "\n",
    "TPOT will generate a Python script that defines the best pipeline discovered during the optimization process. This allows you to save and reuse the pipeline in future projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4m766ZwtsWGX"
   },
   "outputs": [],
   "source": [
    "# Export the pipeline as a Python script\n",
    "tpot.export('tpot_best_pipeline.py')\n",
    "\n",
    "# The pipeline is saved to 'tpot_best_pipeline.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G11ws5n9sWGX"
   },
   "source": [
    "**Observation**: Recall for the minority class improves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGNEtARmsWGY"
   },
   "source": [
    "### **5. Interpreting the Optimized Pipeline**\n",
    "\n",
    "Let’s examine the content of the exported pipeline to understand which model and preprocessing steps were selected by TPOT.\n",
    "\n",
    "#### **Step 5.1: Load the Exported Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zv9usP3ysWGY",
    "outputId": "7aeb01dc-27ba-4b9b-9641-faac2203c04a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.neural_network import MLPClassifier\n",
      "from sklearn.pipeline import make_pipeline\n",
      "from sklearn.preprocessing import RobustScaler\n",
      "from tpot.export_utils import set_param_recursive\n",
      "\n",
      "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
      "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
      "features = tpot_data.drop('target', axis=1)\n",
      "training_features, testing_features, training_target, testing_target = \\\n",
      "            train_test_split(features, tpot_data['target'], random_state=42)\n",
      "\n",
      "# Average CV score on the training set was: 0.9723734177215189\n",
      "exported_pipeline = make_pipeline(\n",
      "    RobustScaler(),\n",
      "    MLPClassifier(alpha=0.1, learning_rate_init=0.01)\n",
      ")\n",
      "# Fix random state for all the steps in exported pipeline\n",
      "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
      "\n",
      "exported_pipeline.fit(training_features, training_target)\n",
      "results = exported_pipeline.predict(testing_features)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load and display the contents of the exported pipeline\n",
    "with open('tpot_best_pipeline.py', 'r') as file:\n",
    "    pipeline_code = file.read()\n",
    "\n",
    "print(pipeline_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjmwbB74sWGY"
   },
   "source": [
    "**Discussion:** Analyze the pipeline. Look for the preprocessing steps (e.g., scaling, imputation), the model chosen, and any hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2blavbtQsWGY"
   },
   "source": [
    "### **6. Visualizing the Evolution of the Genetic Algorithm**\n",
    "\n",
    "TPOT logs the performance of each generation during the genetic algorithm search. We can visualize how the best pipeline evolves over time.\n",
    "\n",
    "#### **Step 6.1: Visualize Performance Over Generations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rdRK8DtNsWGY",
    "outputId": "9f5e4738-ec7b-446e-e64f-97c1b122e9a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'generation', 'mutation_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'mutation_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'mutation_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'mutation_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'mutation_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count', 'crossover_count']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the scores from TPOT's internal log\n",
    "generation_scores = tpot.evaluated_individuals_\n",
    "\n",
    "# Visualize the performance of pipelines across generations\n",
    "generations = list(range(1, len(generation_scores) + 1))\n",
    "\n",
    "best_scores = [\n",
    "    min(\n",
    "        {k: v for k, v in generation_scores[generation].items() if isinstance(v, int)},\n",
    "        key=generation_scores[generation].get\n",
    "    )\n",
    "    for generation in generation_scores\n",
    "]\n",
    "print([min({k: v for k, v in generation_scores[generation].items() if isinstance(v, int)},key=generation_scores[generation].get) for generation in generation_scores])\n",
    "plt.plot(generations, best_scores)\n",
    "plt.title(\"TPOT Pipeline Performance Over Generations\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Best Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxR237sIsWGY"
   },
   "source": [
    "### **7. Hyperparameter Tuning with TPOT**\n",
    "\n",
    "TPOT offers several hyperparameters that can be fine-tuned to control the optimization process.\n",
    "\n",
    "#### **Step 7.1: Experiment with Different Hyperparameters**\n",
    "\n",
    "•\tTry different values for generations, population_size, or mutation_rate to see how they affect the performance and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Yio6aSIBsWGY",
    "outputId": "ab5a90c2-f255-493d-d6b7-79d5211f00f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                             \n",
      "Generation 1 - Current best internal CV score: 0.9748101265822784\n",
      "                                                                              \n",
      "Generation 2 - Current best internal CV score: 0.9748101265822784\n",
      "                                                                              \n",
      "Generation 3 - Current best internal CV score: 0.9748417721518987\n",
      "                                                                              \n",
      "Generation 4 - Current best internal CV score: 0.9748417721518987\n",
      "                                                                              \n",
      "Generation 5 - Current best internal CV score: 0.9748417721518987\n",
      "                                                                              \n",
      "Generation 6 - Current best internal CV score: 0.9748417721518987\n",
      "                                                                              \n",
      "Generation 7 - Current best internal CV score: 0.9748417721518987\n",
      "                                                                              \n",
      "Generation 8 - Current best internal CV score: 0.9748417721518987\n",
      "                                                                              \n",
      "Generation 9 - Current best internal CV score: 0.9748734177215189\n",
      "                                                                              \n",
      "Generation 10 - Current best internal CV score: 0.9748734177215189\n",
      "                                                                              \n",
      "Best pipeline: MLPClassifier(MaxAbsScaler(RobustScaler(MaxAbsScaler(input_matrix))), alpha=0.0001, learning_rate_init=1.0)\n",
      "Test Accuracy after tuning: 98.83%\n"
     ]
    }
   ],
   "source": [
    "# Adjust the hyperparameters and re-run TPOT\n",
    "tpot_tuned = TPOTClassifier(\n",
    "    generations=10,        # Increase generations for a longer search\n",
    "    population_size=50,     # Increase population size for more diversity\n",
    "    verbosity=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "tpot_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_score_tuned = tpot_tuned.score(X_test, y_test)\n",
    "print(f\"Test Accuracy after tuning: {test_score_tuned * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiplIvpasWGY"
   },
   "source": [
    "**Discussion:**\n",
    "\n",
    "•\tHow do different values of generations and population_size affect the final accuracy?\n",
    "\n",
    "•\tDoes a larger population size improve the quality of the final pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPdQ351GsWGZ"
   },
   "source": [
    "### **8. Feature Importance and Interpretability**\n",
    "\n",
    "While TPOT automates the pipeline discovery process, it’s also useful to understand the importance of features in the final model.\n",
    "\n",
    "#### **Step 8.1: Feature Importance for Tree-Based Models**\n",
    "\n",
    "If the best model in the pipeline is tree-based (e.g., Random Forest or XGBoost), you can access feature importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QvFp4tYqsWGZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Check if the best model is tree-based, then calculate feature importance\n",
    "best_model = tpot.fitted_pipeline_.steps[-1][1]\n",
    "\n",
    "if isinstance(best_model, RandomForestClassifier):\n",
    "    feature_importance = best_model.feature_importances_\n",
    "    # Create a DataFrame to display feature importance\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Display feature importance\n",
    "    print(feature_importance_df)\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "    plt.title('Feature Importance')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7M9YYqyVsWGZ"
   },
   "source": [
    "**Discussion:**\n",
    "\n",
    "•\tWhich features are most important in the final model?\n",
    "\n",
    "•\tDoes this align with your intuition about the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2skyg1DsWGZ"
   },
   "source": [
    "## **Homework**\n",
    "\n",
    "Try TPOT on Different Datasets:\n",
    "\n",
    "•\tDownload and load a new dataset, such as the Iris dataset or the Titanic dataset\n",
    "\n",
    "•\tUse TPOT to optimize the machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.3.4)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Path to dataset files: /home/codespace/.cache/kagglehub/datasets/yasserh/titanic-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"yasserh/titanic-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "X = pd.read_csv(os.path.join(path + \"/Titanic-Dataset.csv\"))\n",
    "y = pd.Series(X[\"Survived\"])\n",
    "del(X[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      " PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values:\\n\", X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  22.0      1      0   7.2500        S\n",
       "1       1  female  38.0      1      0  71.2833        C\n",
       "2       3  female  26.0      0      0   7.9250        S\n",
       "3       1  female  35.0      1      0  53.1000        S\n",
       "4       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete some columns\n",
    "X = X.drop(columns=['Cabin', 'PassengerId','Name', 'Ticket'])\n",
    "\n",
    "# Display the first few rows to confirm the column is deleted\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  Embarked_C  \\\n",
       "0         3  22.0      1      0   7.2500         0.0       1.0         0.0   \n",
       "1         1  38.0      1      0  71.2833         1.0       0.0         1.0   \n",
       "2         3  26.0      0      0   7.9250         1.0       0.0         0.0   \n",
       "3         1  35.0      1      0  53.1000         1.0       0.0         0.0   \n",
       "4         3  35.0      0      0   8.0500         0.0       1.0         0.0   \n",
       "..      ...   ...    ...    ...      ...         ...       ...         ...   \n",
       "886       2  27.0      0      0  13.0000         0.0       1.0         0.0   \n",
       "887       1  19.0      0      0  30.0000         1.0       0.0         0.0   \n",
       "888       3   NaN      1      2  23.4500         1.0       0.0         0.0   \n",
       "889       1  26.0      0      0  30.0000         0.0       1.0         1.0   \n",
       "890       3  32.0      0      0   7.7500         0.0       1.0         0.0   \n",
       "\n",
       "     Embarked_Q  Embarked_S  Embarked_nan  \n",
       "0           0.0         1.0           0.0  \n",
       "1           0.0         0.0           0.0  \n",
       "2           0.0         1.0           0.0  \n",
       "3           0.0         1.0           0.0  \n",
       "4           0.0         1.0           0.0  \n",
       "..          ...         ...           ...  \n",
       "886         0.0         1.0           0.0  \n",
       "887         0.0         1.0           0.0  \n",
       "888         0.0         1.0           0.0  \n",
       "889         0.0         0.0           0.0  \n",
       "890         1.0         0.0           0.0  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the OneHotEncoder with sparse_output set to False\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_data = encoder.fit_transform(X[[\"Sex\",'Embarked']])\n",
    "\n",
    "# Create a DataFrame from the encoded data\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out([\"Sex\",'Embarked']))\n",
    "\n",
    "# Bind the encoded DataFrame back to the original DataFrame (excluding the original columns that were encoded)\n",
    "X = pd.concat([X.drop(columns=[\"Sex\", \"Embarked\"]), encoded_df], axis=1)\n",
    "\n",
    "# Display the new DataFrame\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81.8583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  Embarked_C  \\\n",
       "445       1   4.0      0      2  81.8583         0.0       1.0         0.0   \n",
       "650       3   NaN      0      0   7.8958         0.0       1.0         0.0   \n",
       "172       3   1.0      1      1  11.1333         1.0       0.0         0.0   \n",
       "450       2  36.0      1      2  27.7500         0.0       1.0         0.0   \n",
       "314       2  43.0      1      1  26.2500         0.0       1.0         0.0   \n",
       "\n",
       "     Embarked_Q  Embarked_S  Embarked_nan  \n",
       "445         0.0         1.0           0.0  \n",
       "650         0.0         1.0           0.0  \n",
       "172         0.0         1.0           0.0  \n",
       "450         0.0         1.0           0.0  \n",
       "314         0.0         1.0           0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (623, 11)\n",
      "Shape of y_train: (623,)\n",
      "\n",
      "Missing values:\n",
      " Pclass            0\n",
      "Age             124\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Fare              0\n",
      "Sex_female        0\n",
      "Sex_male          0\n",
      "Embarked_C        0\n",
      "Embarked_Q        0\n",
      "Embarked_S        0\n",
      "Embarked_nan      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the dataset\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\\n\", X_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>623.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>623.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.341894</td>\n",
       "      <td>29.256353</td>\n",
       "      <td>0.576244</td>\n",
       "      <td>0.386838</td>\n",
       "      <td>31.840730</td>\n",
       "      <td>0.341894</td>\n",
       "      <td>0.658106</td>\n",
       "      <td>0.176565</td>\n",
       "      <td>0.088283</td>\n",
       "      <td>0.733547</td>\n",
       "      <td>0.001605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.819945</td>\n",
       "      <td>14.558567</td>\n",
       "      <td>1.216267</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>51.027372</td>\n",
       "      <td>0.474725</td>\n",
       "      <td>0.474725</td>\n",
       "      <td>0.381607</td>\n",
       "      <td>0.283933</td>\n",
       "      <td>0.442459</td>\n",
       "      <td>0.040064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.925000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass         Age       SibSp       Parch        Fare  Sex_female  \\\n",
       "count  623.000000  499.000000  623.000000  623.000000  623.000000  623.000000   \n",
       "mean     2.341894   29.256353    0.576244    0.386838   31.840730    0.341894   \n",
       "std      0.819945   14.558567    1.216267    0.807692   51.027372    0.474725   \n",
       "min      1.000000    0.420000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      2.000000   20.000000    0.000000    0.000000    7.925000    0.000000   \n",
       "50%      3.000000   28.000000    0.000000    0.000000   14.454200    0.000000   \n",
       "75%      3.000000   38.000000    1.000000    0.000000   30.750000    1.000000   \n",
       "max      3.000000   80.000000    8.000000    6.000000  512.329200    1.000000   \n",
       "\n",
       "         Sex_male  Embarked_C  Embarked_Q  Embarked_S  Embarked_nan  \n",
       "count  623.000000  623.000000  623.000000  623.000000    623.000000  \n",
       "mean     0.658106    0.176565    0.088283    0.733547      0.001605  \n",
       "std      0.474725    0.381607    0.283933    0.442459      0.040064  \n",
       "min      0.000000    0.000000    0.000000    0.000000      0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000      0.000000  \n",
       "50%      1.000000    0.000000    0.000000    1.000000      0.000000  \n",
       "75%      1.000000    0.000000    0.000000    1.000000      0.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000      1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic statistics of the dataset\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values in feature set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                             \n",
      "Generation 1 - Current best internal CV score: 0.8201935483870969\n",
      "                                                                              \n",
      "Generation 2 - Current best internal CV score: 0.8217548387096775\n",
      "                                                                              \n",
      "Generation 3 - Current best internal CV score: 0.8266580645161291\n",
      "                                                                              \n",
      "Generation 4 - Current best internal CV score: 0.8266580645161291\n",
      "                                                                              \n",
      "Generation 5 - Current best internal CV score: 0.8266580645161291\n",
      "                                                                              \n",
      "Generation 6 - Current best internal CV score: 0.8298193548387097\n",
      "                                                                              \n",
      "Generation 7 - Current best internal CV score: 0.8298193548387097\n",
      "                                                                              \n",
      "Generation 8 - Current best internal CV score: 0.8298193548387097\n",
      "                                                                              \n",
      "Generation 9 - Current best internal CV score: 0.8298193548387097\n",
      "                                                                              \n",
      "Generation 10 - Current best internal CV score: 0.8314322580645161\n",
      "                                                                              \n",
      "Best pipeline: RandomForestClassifier(input_matrix, bootstrap=False, criterion=gini, max_features=0.15000000000000002, min_samples_leaf=7, min_samples_split=10, n_estimators=100)\n",
      "Imputing missing values in feature set\n",
      "Test Accuracy after tuning: 79.85%\n"
     ]
    }
   ],
   "source": [
    "# Adjust the hyperparameters and re-run TPOT\n",
    "tpot_tuned = TPOTClassifier(\n",
    "    generations=10,        # Increase generations for a longer search\n",
    "    population_size=50,     # Increase population size for more diversity\n",
    "    verbosity=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "tpot_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_score_tuned = tpot_tuned.score(X_test, y_test)\n",
    "print(f\"Test Accuracy after tuning: {test_score_tuned * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.neural_network import MLPClassifier\n",
      "from sklearn.pipeline import make_pipeline\n",
      "from sklearn.preprocessing import RobustScaler\n",
      "from tpot.export_utils import set_param_recursive\n",
      "\n",
      "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
      "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
      "features = tpot_data.drop('target', axis=1)\n",
      "training_features, testing_features, training_target, testing_target = \\\n",
      "            train_test_split(features, tpot_data['target'], random_state=42)\n",
      "\n",
      "# Average CV score on the training set was: 0.9723734177215189\n",
      "exported_pipeline = make_pipeline(\n",
      "    RobustScaler(),\n",
      "    MLPClassifier(alpha=0.1, learning_rate_init=0.01)\n",
      ")\n",
      "# Fix random state for all the steps in exported pipeline\n",
      "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
      "\n",
      "exported_pipeline.fit(training_features, training_target)\n",
      "results = exported_pipeline.predict(testing_features)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Export the pipeline\n",
    "tpot.export('tpot_best_pipeline_homework.py')\n",
    "\n",
    "# Load and display the contents of the exported pipeline\n",
    "with open('tpot_best_pipeline_homework.py', 'r') as file:\n",
    "    pipeline_code = file.read()\n",
    "\n",
    "print(pipeline_code)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
